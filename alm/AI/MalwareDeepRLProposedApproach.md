# Proposed Approach 



## Brief Summary 

The proposed model utilizes a deep reinforcement learning architecture to implement a vision attention based binomial malware classification system.  The system is fundamentally composed of multiple processes, each process vitally contributing to the whole.  The core processes are broken down and novelties are described in detail below. 



## Convolutional Neural Network 

A convolutional neural network (CNN) architecture is a class of deep neural networks commonly utilized in image analysis and classification.  A CNN is essentially composed of convolution layers and pooling layers. The convolution layers use filtering to extract features from a raw image. Pooling layers reduce the dimensions of the feature map, therein scaling down the number of parameters and minimizing computation. CNN’s contain the ability  to   autonomously learn feature representation from raw data. This allows the model to learn abstract features from a provided set of training data and apply feature representation in classifying testing data.



## Reinforcement Learning 

<<<<<<< HEAD
Reinforcement learning is a subsection of machine learning focused on the mapping of optimal actions to specific environment states, in aim of augmenting reward.  An agent is placed within an environment and equipped with a finite set of possible actions.  Through repetition the agent learns optimal behavior within states. The foundation of reinforcement learning is the reward function, which drives the agent to pursue directed goals. Q-Learning is a reinforcement learning architecture which is concerned with the identification of optimal action-selection policies for any given Markov Decision Process. A Markov Decision Process is a mathematical framework for modeling decision making in discrete time. The Markov Decision Process is a 4-tuple: 
=======
Reinforcement learning is a subsection of machine learning focused on the mapping of optimal actions to specific environment states, in aim of augmenting reward. 4
>>>>>>> adc77d09ccafdf17e81601d339e3860ad8760fa4

​	(S,A,Pa, Ra) ** Define Variables Wiki**  

A Q-Table is established for the agent, mapping the action that maximizes reward to each possible state. The reward, referred to as the Q value, can be formalized using the Bellman Equation, as seen in Equation XXX.  Essentially, the Q value is equal to the immediate reward  in addition to the long-term reward multiplied by a discount factor(LAMDA), that stresses the importance of long-term reward versus immediate reward. 



Talk more about generic RL and algorithm + Q learning equations + Environment + Agent

## Vision Attention Based Deep Reinforcement Learning Model

The proposed Deep Reinforcement Learning based vision attention architecture is embodied by three vital stages, namely data processing, image augmentation, and core model training.  

The core model involves the use of an agent who chooses from a finite set of actions, each of which influence the environment and carry the agent from one state to the other. The environment is a visualized set of operational codes. 



### Data Processing





### Image Augmentation

The proposed architecture is grounded on the assumption that the dataset contains as many images as possible that have already been focused.  In order to implement this a systematic procedure was followed, ensuring that each training image was exposed to as many actions  



### Core DRL Model 

